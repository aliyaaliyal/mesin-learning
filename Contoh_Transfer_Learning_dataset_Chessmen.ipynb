{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5mxjiiUJq2Hc86WgO8Hd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliyaaliyal/mesin-learning/blob/main/Contoh_Transfer_Learning_dataset_Chessmen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CryMw9bxVQKS",
        "outputId": "f93e0130-0421-40dd-8cd8-765f1a6f063d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-24 15:52:28--  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip [following]\n",
            "--2022-11-24 15:52:28--  https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M   244MB/s    in 0.2s    \n",
            "\n",
            "2022-11-24 15:52:30 (244 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')"
      ],
      "metadata": {
        "id": "6jce9BHNV5gC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.1) # set validation split"
      ],
      "metadata": {
        "id": "TIYmpQ8gV_dY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagi dataset menjadi data training dan data validasi."
      ],
      "metadata": {
        "id": "u-4oRZNmWF2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxaDN_gRWGvz",
        "outputId": "4a9ef846-7431-442a-a453-c1bdae3a23fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 499 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvz8VwJEWK_T",
        "outputId": "a67f597f-3678-43e0-9260-d3bf8fc21bd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 52 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang digunakan adalah ResNet152V2, dimana model ini memiliki 152 layer dan tersedia di library keras.\n",
        "\n",
        "Untuk mengimplementasikan transfer learning, Kita hanya perlu menambahkan 2 buah baris kode berbeda. Layer pertama pada model kita adalah model yang di pakai untuk transfer learning. Kita cukup memanggil kelas ResNet152V2 dan mengisi parameter: weight, include_top dan input_tensor."
      ],
      "metadata": {
        "id": "cLPrxYHjWeSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2"
      ],
      "metadata": {
        "id": "wyqadA5sWOv5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')  \n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLyG6GiFXFCH",
        "outputId": "41ba3843-ef32-4eca-ed63-b6c7996833c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "_KiYVzENXLHX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "selanjutnya menentukan optimizer, loss, serta metrik yang akan digunakan pada model."
      ],
      "metadata": {
        "id": "a5ehfkI0XTrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "EXktNcRDXYlI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "melatih model"
      ],
      "metadata": {
        "id": "lgYqrX_6Xfen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPyI08LRXh5U",
        "outputId": "1c85c047-bb2e-4d19-9e76-09138a379cb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 94s - loss: 10.0585 - accuracy: 0.4770 - val_loss: 3.4328 - val_accuracy: 0.5385 - 94s/epoch - 1s/step\n",
            "Epoch 2/50\n",
            "63/63 - 83s - loss: 1.5738 - accuracy: 0.7174 - val_loss: 1.3439 - val_accuracy: 0.5577 - 83s/epoch - 1s/step\n",
            "Epoch 3/50\n",
            "63/63 - 84s - loss: 1.1023 - accuracy: 0.7315 - val_loss: 0.9915 - val_accuracy: 0.7308 - 84s/epoch - 1s/step\n",
            "Epoch 4/50\n",
            "63/63 - 84s - loss: 0.6917 - accuracy: 0.8176 - val_loss: 0.8920 - val_accuracy: 0.7308 - 84s/epoch - 1s/step\n",
            "Epoch 5/50\n",
            "63/63 - 84s - loss: 0.6825 - accuracy: 0.8216 - val_loss: 1.6774 - val_accuracy: 0.6346 - 84s/epoch - 1s/step\n",
            "Epoch 6/50\n",
            "63/63 - 84s - loss: 0.5662 - accuracy: 0.8457 - val_loss: 1.9721 - val_accuracy: 0.5962 - 84s/epoch - 1s/step\n",
            "Epoch 7/50\n",
            "63/63 - 83s - loss: 0.8093 - accuracy: 0.7956 - val_loss: 1.3043 - val_accuracy: 0.6538 - 83s/epoch - 1s/step\n",
            "Epoch 8/50\n",
            "63/63 - 84s - loss: 0.4960 - accuracy: 0.8858 - val_loss: 0.8072 - val_accuracy: 0.7885 - 84s/epoch - 1s/step\n",
            "Epoch 9/50\n",
            "63/63 - 83s - loss: 0.5599 - accuracy: 0.8818 - val_loss: 0.9493 - val_accuracy: 0.7692 - 83s/epoch - 1s/step\n",
            "Epoch 10/50\n",
            "63/63 - 84s - loss: 0.3015 - accuracy: 0.8998 - val_loss: 0.8616 - val_accuracy: 0.8269 - 84s/epoch - 1s/step\n",
            "Epoch 11/50\n",
            "63/63 - 84s - loss: 0.4632 - accuracy: 0.8918 - val_loss: 1.0259 - val_accuracy: 0.7500 - 84s/epoch - 1s/step\n",
            "Epoch 12/50\n",
            "63/63 - 83s - loss: 0.3639 - accuracy: 0.9058 - val_loss: 1.7057 - val_accuracy: 0.6731 - 83s/epoch - 1s/step\n",
            "Epoch 13/50\n",
            "63/63 - 84s - loss: 0.3016 - accuracy: 0.9118 - val_loss: 1.0740 - val_accuracy: 0.7885 - 84s/epoch - 1s/step\n",
            "Epoch 14/50\n",
            "63/63 - 84s - loss: 0.5346 - accuracy: 0.8978 - val_loss: 1.2042 - val_accuracy: 0.7500 - 84s/epoch - 1s/step\n",
            "Epoch 15/50\n",
            "63/63 - 83s - loss: 0.6370 - accuracy: 0.8918 - val_loss: 4.2349 - val_accuracy: 0.5577 - 83s/epoch - 1s/step\n",
            "Epoch 16/50\n",
            "63/63 - 84s - loss: 0.4541 - accuracy: 0.8958 - val_loss: 1.1909 - val_accuracy: 0.7308 - 84s/epoch - 1s/step\n",
            "Epoch 17/50\n",
            "63/63 - 83s - loss: 0.2509 - accuracy: 0.9359 - val_loss: 2.9041 - val_accuracy: 0.6346 - 83s/epoch - 1s/step\n",
            "Epoch 18/50\n",
            "63/63 - 84s - loss: 0.4782 - accuracy: 0.9058 - val_loss: 1.9841 - val_accuracy: 0.6731 - 84s/epoch - 1s/step\n",
            "Epoch 19/50\n",
            "63/63 - 84s - loss: 0.4592 - accuracy: 0.9198 - val_loss: 0.6654 - val_accuracy: 0.7692 - 84s/epoch - 1s/step\n",
            "Epoch 20/50\n",
            "63/63 - 84s - loss: 0.3033 - accuracy: 0.9279 - val_loss: 1.4587 - val_accuracy: 0.8077 - 84s/epoch - 1s/step\n",
            "Epoch 21/50\n",
            "63/63 - 85s - loss: 0.2710 - accuracy: 0.9158 - val_loss: 1.3682 - val_accuracy: 0.6538 - 85s/epoch - 1s/step\n",
            "Epoch 22/50\n",
            "63/63 - 84s - loss: 0.3720 - accuracy: 0.9238 - val_loss: 1.1846 - val_accuracy: 0.7885 - 84s/epoch - 1s/step\n",
            "Epoch 23/50\n",
            "63/63 - 85s - loss: 0.2330 - accuracy: 0.9419 - val_loss: 1.4383 - val_accuracy: 0.6923 - 85s/epoch - 1s/step\n",
            "Epoch 24/50\n",
            "63/63 - 84s - loss: 0.2376 - accuracy: 0.9339 - val_loss: 0.7442 - val_accuracy: 0.8077 - 84s/epoch - 1s/step\n",
            "Epoch 25/50\n",
            "63/63 - 84s - loss: 0.3588 - accuracy: 0.9218 - val_loss: 0.9130 - val_accuracy: 0.8462 - 84s/epoch - 1s/step\n",
            "Epoch 26/50\n",
            "63/63 - 85s - loss: 0.1108 - accuracy: 0.9659 - val_loss: 1.7515 - val_accuracy: 0.6538 - 85s/epoch - 1s/step\n",
            "Epoch 27/50\n",
            "63/63 - 84s - loss: 0.0918 - accuracy: 0.9679 - val_loss: 0.8023 - val_accuracy: 0.7885 - 84s/epoch - 1s/step\n",
            "Epoch 28/50\n",
            "63/63 - 85s - loss: 0.0989 - accuracy: 0.9679 - val_loss: 1.0024 - val_accuracy: 0.8077 - 85s/epoch - 1s/step\n",
            "Epoch 29/50\n",
            "63/63 - 84s - loss: 0.1652 - accuracy: 0.9599 - val_loss: 1.6319 - val_accuracy: 0.7692 - 84s/epoch - 1s/step\n",
            "Epoch 30/50\n",
            "63/63 - 85s - loss: 0.0790 - accuracy: 0.9760 - val_loss: 1.2545 - val_accuracy: 0.7500 - 85s/epoch - 1s/step\n",
            "Epoch 31/50\n",
            "63/63 - 84s - loss: 0.0923 - accuracy: 0.9719 - val_loss: 0.4809 - val_accuracy: 0.8269 - 84s/epoch - 1s/step\n",
            "Epoch 32/50\n",
            "63/63 - 85s - loss: 0.1776 - accuracy: 0.9559 - val_loss: 0.5629 - val_accuracy: 0.8462 - 85s/epoch - 1s/step\n",
            "Epoch 33/50\n",
            "63/63 - 86s - loss: 0.1421 - accuracy: 0.9579 - val_loss: 0.8228 - val_accuracy: 0.7692 - 86s/epoch - 1s/step\n",
            "Epoch 34/50\n",
            "63/63 - 87s - loss: 0.1626 - accuracy: 0.9619 - val_loss: 0.9889 - val_accuracy: 0.8077 - 87s/epoch - 1s/step\n",
            "Epoch 35/50\n",
            "63/63 - 85s - loss: 0.3856 - accuracy: 0.9339 - val_loss: 2.1962 - val_accuracy: 0.6731 - 85s/epoch - 1s/step\n",
            "Epoch 36/50\n",
            "63/63 - 86s - loss: 0.4552 - accuracy: 0.9098 - val_loss: 0.5140 - val_accuracy: 0.8462 - 86s/epoch - 1s/step\n",
            "Epoch 37/50\n",
            "63/63 - 85s - loss: 0.2541 - accuracy: 0.9479 - val_loss: 1.9977 - val_accuracy: 0.8077 - 85s/epoch - 1s/step\n",
            "Epoch 38/50\n",
            "63/63 - 86s - loss: 0.4464 - accuracy: 0.9339 - val_loss: 2.0412 - val_accuracy: 0.7500 - 86s/epoch - 1s/step\n",
            "Epoch 39/50\n",
            "63/63 - 85s - loss: 0.2963 - accuracy: 0.9399 - val_loss: 1.9034 - val_accuracy: 0.6923 - 85s/epoch - 1s/step\n",
            "Epoch 40/50\n",
            "63/63 - 85s - loss: 0.1378 - accuracy: 0.9599 - val_loss: 1.1235 - val_accuracy: 0.8077 - 85s/epoch - 1s/step\n",
            "Epoch 41/50\n",
            "63/63 - 85s - loss: 0.1068 - accuracy: 0.9699 - val_loss: 1.1372 - val_accuracy: 0.7692 - 85s/epoch - 1s/step\n",
            "Epoch 42/50\n",
            "63/63 - 85s - loss: 0.1629 - accuracy: 0.9579 - val_loss: 1.0708 - val_accuracy: 0.7500 - 85s/epoch - 1s/step\n",
            "Epoch 43/50\n",
            "63/63 - 86s - loss: 0.2668 - accuracy: 0.9379 - val_loss: 1.6008 - val_accuracy: 0.7692 - 86s/epoch - 1s/step\n",
            "Epoch 44/50\n",
            "63/63 - 85s - loss: 0.2166 - accuracy: 0.9519 - val_loss: 1.1525 - val_accuracy: 0.7885 - 85s/epoch - 1s/step\n",
            "Epoch 45/50\n",
            "63/63 - 86s - loss: 0.1566 - accuracy: 0.9619 - val_loss: 0.5873 - val_accuracy: 0.7885 - 86s/epoch - 1s/step\n",
            "Epoch 46/50\n",
            "63/63 - 85s - loss: 0.0779 - accuracy: 0.9760 - val_loss: 0.6974 - val_accuracy: 0.8654 - 85s/epoch - 1s/step\n",
            "Epoch 47/50\n",
            "63/63 - 86s - loss: 0.1298 - accuracy: 0.9699 - val_loss: 1.2064 - val_accuracy: 0.7885 - 86s/epoch - 1s/step\n",
            "Epoch 48/50\n",
            "63/63 - 85s - loss: 0.1578 - accuracy: 0.9559 - val_loss: 1.1083 - val_accuracy: 0.8269 - 85s/epoch - 1s/step\n",
            "Epoch 49/50\n",
            "63/63 - 85s - loss: 0.3207 - accuracy: 0.9419 - val_loss: 1.7749 - val_accuracy: 0.7500 - 85s/epoch - 1s/step\n",
            "Epoch 50/50\n",
            "63/63 - 86s - loss: 0.1120 - accuracy: 0.9760 - val_loss: 0.7543 - val_accuracy: 0.8269 - 86s/epoch - 1s/step\n"
          ]
        }
      ]
    }
  ]
}